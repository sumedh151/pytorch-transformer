{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumedh151/pytorch-transformer/blob/main/run_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKDzbQizKi3S",
        "outputId": "445a2000-daeb-4d3d-f9aa-be1c669ea4c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading readme: 100% 3.14k/3.14k [00:00<00:00, 9.17MB/s]\n",
            "Downloading metadata: 100% 953/953 [00:00<00:00, 5.88MB/s]\n",
            "Downloading data: 100% 190M/190M [00:13<00:00, 13.6MB/s]\n",
            "Downloading data: 100% 85.7k/85.7k [00:01<00:00, 49.1kB/s]\n",
            "Downloading data: 100% 500k/500k [00:02<00:00, 235kB/s]\n",
            "Generating train split: 100% 1659083/1659083 [00:02<00:00, 687765.29 examples/s]\n",
            "Generating validation split: 100% 520/520 [00:00<00:00, 124538.23 examples/s]\n",
            "Generating test split: 100% 2507/2507 [00:00<00:00, 270603.74 examples/s]\n",
            "{'translation': {'en': 'Give your application an accessibility workout', 'hi': '‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç'}}\n",
            "{'en': 'Give your application an accessibility workout', 'hi': '‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç'}\n",
            "Give your application an accessibility workout\n",
            "‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç\n",
            "hello world\n",
            "{'NUM_HEADS': 10}\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/Colab\\ Notebooks/attention\\ is\\ all\\ you\\ need/main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as8WCnkvKdhj",
        "outputId": "bb6c93ee-41f0-4dce-9b40-342557331545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting requests>=2.32.1 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.1->datasets) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, requests, dill, multiprocess, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.19.2 dill-0.3.8 multiprocess-0.70.16 requests-2.32.3 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhJ7LBCB2SCr"
      },
      "outputs": [],
      "source": [
        "# https://www.youtube.com/watch?v=ISNdQcPhsts\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "# from config import config\n",
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYn0gcjkc_5W",
        "outputId": "5a08b9e1-3dc0-4b4a-da5a-56d0cc472a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'translation': {'en': 'Give your application an accessibility workout', 'hi': '‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç'}}\n",
            "{'en': 'Give your application an accessibility workout', 'hi': '‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç'}\n",
            "Give your application an accessibility workout\n",
            "‡§Ö‡§™‡§®‡•á ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§™‡§π‡•Å‡§Ç‡§ö‡§®‡•Ä‡§Ø‡§§‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§¶‡•á‡§Ç\n",
            "hello world\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\", split='train')\n",
        "\n",
        "print(dataset[0])\n",
        "print(dataset[0]['translation'])\n",
        "print(dataset[0]['translation']['en'])\n",
        "print(dataset[0]['translation']['hi'])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('hello world')\n",
        "    # print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbZwHeElOY5J",
        "outputId": "dc39905a-4bdd-44d0-df03-4604e3e009fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['translation'],\n",
              "    num_rows: 1659083\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPi1w8CxmaPG"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors\n",
        "\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
        "\n",
        "# def get_texts(dataset, lang):\n",
        "def get_texts(dataset):\n",
        "    for example in dataset['train']['translation']:\n",
        "        # yield example[lang]\n",
        "        yield example['en']\n",
        "        yield example['hi']\n",
        "\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "tokenizer.post_processor = processors.ByteLevel()\n",
        "\n",
        "trainer = trainers.BpeTrainer(special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "\n",
        "# tokenizer.train_from_iterator(get_texts(dataset, 'en'), trainer=trainer)\n",
        "# tokenizer.train_from_iterator(get_texts(dataset, 'hi'), trainer=trainer)\n",
        "tokenizer.train_from_iterator(get_texts(dataset), trainer=trainer)\n",
        "\n",
        "tokenizer.save(\"iitb-english-hindi-tokenizer.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x6UTncTykhG",
        "outputId": "9707a3b2-6048-4e51-c428-55c6d5aa6ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 's', 'ƒ†', 'i', 's', 'ƒ†', 'a', 'ƒ†', 't', 'e', 's', 't', 'ƒ†', 's', 'e', 'n', 't', 'e', 'n', 'c', 'e']\n"
          ]
        }
      ],
      "source": [
        "# Encode some text\n",
        "encoding = tokenizer.encode(\"This is a test sentence.\")\n",
        "print(encoding.tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y4vhMaBz4DT",
        "outputId": "de1de241-085c-43dc-93f6-3a51dec2622a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "tokenizer.get_vocab_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DHrj6dnyVUY",
        "outputId": "52def21a-1be3-44b5-9470-47a8944bba96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'ƒ†is', 'ƒ†a', 'ƒ†test', 'ƒ†sentence', '.']\n",
            "This is a test sentence.\n"
          ]
        }
      ],
      "source": [
        "# Load the trained tokenizer\n",
        "tokenizer = Tokenizer.from_file(\"iitb-english-hindi-tokenizer.json\")\n",
        "\n",
        "# Encode some text\n",
        "encoding = tokenizer.encode(\"This is a test sentence.\")\n",
        "print(encoding.tokens)\n",
        "\n",
        "# Decode back to text\n",
        "decoded_text = tokenizer.decode(encoding.ids)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tsE54k5ljv7",
        "outputId": "b0e7dc05-74d1-4868-9f92-02fd9f81adc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'ƒ†is', 'ƒ†a', 'ƒ†test', 'ƒ†sentence', '.']\n",
            "This is a test sentence.\n"
          ]
        }
      ],
      "source": [
        "# Load the trained tokenizer\n",
        "tokenizer = Tokenizer.from_file(\"iitb-english-hindi-tokenizer.json\")\n",
        "\n",
        "# Encode some text\n",
        "encoding = tokenizer.encode(\"This is a test sentence.\")\n",
        "print(encoding.tokens)\n",
        "\n",
        "# Decode back to text\n",
        "decoded_text = tokenizer.decode(encoding.ids)\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqeuI7AI3yyl",
        "outputId": "b9fc3cc1-b003-420f-9bc9-01a1564239c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1659083\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 520\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 2507\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qKN3HgZ3cnV"
      },
      "outputs": [],
      "source": [
        "class CustomTranslationDataset(Dataset):\n",
        "    def __init__(self, split='train'):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zemIYMmS31m5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "83a2ee65-1dd7-4c79-af7f-edc4c5b25c9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.CustomTranslationDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>CustomTranslationDataset</b><br/>def __init__(split=&#x27;train&#x27;)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\"></a>An abstract class representing a :class:`Dataset`.\n",
              "\n",
              "All datasets that represent a map from keys to data samples should subclass\n",
              "it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
              "data sample for a given key. Subclasses could also optionally overwrite\n",
              ":meth:`__len__`, which is expected to return the size of the dataset by many\n",
              ":class:`~torch.utils.data.Sampler` implementations and the default options\n",
              "of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
              "optionally implement :meth:`__getitems__`, for speedup batched samples\n",
              "loading. This method accepts list of indices of samples of batch and returns\n",
              "list of samples.\n",
              "\n",
              ".. note::\n",
              "  :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
              "  sampler that yields integral indices.  To make it work with a map-style\n",
              "  dataset with non-integral indices/keys, a custom sampler must be provided.</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "CustomTranslationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6u3pyQmqATl",
        "outputId": "717d08a6-087d-4009-e94f-df3e32cbbc58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 1659083\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 520\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['translation'],\n",
              "        num_rows: 2507\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3wYx5GW1ihe"
      },
      "outputs": [],
      "source": [
        "class CustomTranslationDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, split='train'):\n",
        "        self.dataset = dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.split = split\n",
        "        self.tokenized_data = self.tokenize_data()\n",
        "\n",
        "    def tokenize_data(self):\n",
        "        tokens = []\n",
        "        for i in self.dataset[self.split]['translation']:\n",
        "            en_tokens = self.tokenizer.encode(i['en']).ids\n",
        "            hi_tokens = self.tokenizer.encode(i['hi']).ids\n",
        "            tokens.append((en_tokens, hi_tokens))\n",
        "        return tokens\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.tokenized_data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sG1BICgsoZI"
      },
      "outputs": [],
      "source": [
        "ds = CustomTranslationDataset(dataset, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jr3OL7ztRek",
        "outputId": "d5af6a63-58de-4da2-939f-f43c0c28037e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([12879, 593, 2865, 388, 20185, 872, 678], [1435, 207, 421, 230, 237, 208, 721, 217, 244, 210, 217, 543, 891, 679, 213, 575, 205, 252, 208, 219, 205, 219, 205, 223, 210, 205, 277, 205, 316, 271, 246])\n"
          ]
        }
      ],
      "source": [
        "for i in ds:\n",
        "    print(i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESDxpNSZ2mk5",
        "outputId": "0ee8fb96-3eab-420c-e55c-581802539814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give your application an accessibility workout\n",
            "47\n",
            "31\n"
          ]
        }
      ],
      "source": [
        "for i in ds:\n",
        "    print(tokenizer.decode(i[0]))\n",
        "    print(len(tokenizer.decode(i[1])))\n",
        "    print(len(i[1]))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ety_zL27FhU5"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders, processors\n",
        "\n",
        "dataset = load_dataset(\"cfilt/iitb-english-hindi\")\n",
        "\n",
        "def get_texts(dataset, lang):\n",
        "    for example in dataset['train']['translation']:\n",
        "        yield example[lang]\n",
        "\n",
        "tokenizer_en = Tokenizer(models.BPE())\n",
        "tokenizer_en.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "tokenizer_en.decoder = decoders.ByteLevel()\n",
        "tokenizer_en.post_processor = processors.ByteLevel()\n",
        "trainer = trainers.BpeTrainer(special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "tokenizer_en.train_from_iterator(get_texts(dataset, 'en'), trainer=trainer)\n",
        "\n",
        "tokenizer_en.save(\"iitb-english-hindi-tokenizer_en.json\")\n",
        "\n",
        "tokenizer_hi = Tokenizer(models.BPE())\n",
        "tokenizer_hi.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
        "tokenizer_hi.decoder = decoders.ByteLevel()\n",
        "tokenizer_hi.post_processor = processors.ByteLevel()\n",
        "trainer = trainers.BpeTrainer(special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n",
        "tokenizer_hi.train_from_iterator(get_texts(dataset, 'hi'), trainer=trainer)\n",
        "\n",
        "tokenizer_hi.save(\"iitb-english-hindi-tokenizer_hi.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kpauQgxI4Lu",
        "outputId": "a5895cdd-a2d6-4362-d60d-a9652e8d43fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.get_vocab_size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O3wSaG4L3H7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qdn5vaaT94T",
        "outputId": "63d957ab-d5ff-4661-ae4d-fae1680b1c5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([5000, 1, 10])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len=5000\n",
        "# position = torch.arange(max_len).unsqueeze(1)\n",
        "position = torch.zeros((max_len,10))\n",
        "position = torch.zeros((max_len,10)).unsqueeze(1)\n",
        "position.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Softmax(dim=-1)\n",
        "input = torch.randn(2, 3)\n",
        "print(input)\n",
        "output = m(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjt3jlGS0xCD",
        "outputId": "67735ac8-509d-41ac-863e-5be4e7a947b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8562, -1.3840,  0.0435],\n",
            "        [-1.3955, -0.0956, -0.2893]])\n",
            "tensor([[0.2470, 0.1457, 0.6073],\n",
            "        [0.1300, 0.4770, 0.3930]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYa0t3AkTqtA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8ygdhfeRbO7"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE89OACUe182",
        "outputId": "35622ca9-f8b1-42d4-af7b-ee1f8af1b4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[14823, 83, 16, 325, 11, 465, 5], [14823, 83, 16, 325, 11, 465, 5]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# output = tokenizer.encode_batch([\"Hello, y'all!\", \"How are you üòÅ ?\"])\n",
        "output = tokenizer.encode_batch([\"Hello, y'all!\", \"Hello, y'all!\"])\n",
        "output = [x.ids for x in output]\n",
        "print(output)\n",
        "torch.Tensor(output).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUJ9fEjui9pQ"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(PositionalEncoding,self).__init__()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsBhaUc4Tfmy"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "    def forward(self,x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vspiO6yxSh1U"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d, dk, dv, h) -> None:\n",
        "        super(Encoder, self).__init__()\n",
        "        # self.query_weight = nn.Parameter(torch.randn(d, dk), requires_grad=True)\n",
        "        # self.key_weight   = nn.Parameter(torch.randn(d, dk), requires_grad=True)\n",
        "        # self.value_weight = nn.Parameter(torch.randn(d, dv), requires_grad=True)\n",
        "        self.query_layer = nn.Linear(d,dk)\n",
        "        self.key_layer = nn.Linear(d,dk)\n",
        "        self.value_layer = nn.Linear(d,dv)\n",
        "        self.output_layer = nn.Linear(h*dv,d)\n",
        "        self.dk = dk\n",
        "        self.h = h\n",
        "        self.layer_norm1 = nn.LayerNorm(d)\n",
        "        self.layer_norm2 = nn.LayerNorm(d)\n",
        "        self.ff = nn.Linear()\n",
        "\n",
        "\n",
        "    def multihead_attention(self, query, key, value):\n",
        "        # same layers???\n",
        "        head_outputs = []\n",
        "        for _ in range(self.h):\n",
        "            head_output = self.self_attention(query, key, value)\n",
        "            head_outputs.append(head_output)\n",
        "        return torch.concat(head_outputs, dim=-1)\n",
        "\n",
        "    def self_attention(self, query, key, value):\n",
        "        qt = torch.bmm(query, torch.transpose(key,1,2))\n",
        "        attn_weights = nn.Softmax(dim=-1)(qt/np.sqrt(self.dk))\n",
        "        self_attn = torch.bmm(qt, value)\n",
        "        return self_attn\n",
        "\n",
        "    def forward(self,x):\n",
        "        # query = torch.matmul(x, self.query_weight)\n",
        "        # key   = torch.matmul(x, self.key_weight)\n",
        "        # value = torch.matmul(x, self.value_weight)\n",
        "\n",
        "        query = self.query_layer(x)\n",
        "        key   = self.key_layer(x)\n",
        "        value = self.value_layer(x)\n",
        "\n",
        "        multihead_attn = self.multihead_attention(query, key, value)\n",
        "        output = self.output_layer(multihead_attn)\n",
        "        resi1 = output + x\n",
        "        norm1 = self.layer_norm1(resi1)\n",
        "\n",
        "        return resi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv585CzRUBKI"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, tokenizer, nx=6) -> None:\n",
        "        super(Transformer, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.nx = nx\n",
        "        self.d = 256\n",
        "        self.dk = 512\n",
        "        self.dv = 512\n",
        "        self.h = 8\n",
        "        self.inp_embedding = nn.Embedding(tokenizer.get_vocab_size(), self.d, max_norm=True)\n",
        "        self.positional_encoding = PositionalEncoding()\n",
        "        self.encoder = Encoder(d = self.d, dk = self.dk, dv = self.dv, h = self.h)\n",
        "        self.decoder = Decoder()\n",
        "\n",
        "    def forward(self, input_tokens):\n",
        "        x = self.inp_embedding(input_tokens)\n",
        "        x = self.positional_encoding(x)\n",
        "        for _ in range(self.nx):\n",
        "            x = self.encoder(x)\n",
        "            print(x.shape)\n",
        "        # for _ in range(self.nx):\n",
        "        #     x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JntmaNHEgcfc",
        "outputId": "54b281bf-0e0d-4bd5-d6cb-161a325e099c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 7, 256])\n",
            "torch.Size([2, 7, 256])\n",
            "torch.Size([2, 7, 256])\n",
            "torch.Size([2, 7, 256])\n",
            "torch.Size([2, 7, 256])\n",
            "torch.Size([2, 7, 256])\n"
          ]
        }
      ],
      "source": [
        "trans = Transformer(tokenizer)(torch.LongTensor(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxGv6owRgdUU",
        "outputId": "04ef6d2f-b87e-41fc-fbf3-3d0d8961402c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4823e+04, 8.3000e+01, 1.6000e+01, 3.2500e+02, 1.1000e+01, 4.6500e+02,\n",
              "         5.0000e+00],\n",
              "        [1.4823e+04, 8.3000e+01, 1.6000e+01, 3.2500e+02, 1.1000e+01, 4.6500e+02,\n",
              "         5.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "torch.Tensor(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "371dy4Bhk3fC",
        "outputId": "2c3aa235-56f8-4ca1-ef79-d4ec32484b21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[14823,    83,    16,   325,    11,   465,     5],\n",
              "        [14823,    83,    16,   325,    11,   465,     5]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "torch.LongTensor(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3BesgrQk68T",
        "outputId": "f694e32d-9676-49a1-837d-bb623f000792"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[14823,    83,    16,   325,    11,   465,     5],\n",
              "       [14823,    83,    16,   325,    11,   465,     5]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "np.array(output, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfaouILplHaV",
        "outputId": "8455742f-471d-423a-f27e-32a5512f6d02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.Linear(10,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuPLBkAsUU9R"
      },
      "outputs": [],
      "source": [
        "l = nn.Linear(10,20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3AeTun9Uoy1",
        "outputId": "d29d838e-1b4d-4052-eaa0-e56246ce3881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 10])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(128, 32,10)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0MO4PLuVP7z",
        "outputId": "2eb3549e-4221-40b4-df6e-76d2cea02730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 20])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRwen52vVi2Q",
        "outputId": "c8403655-8be0-4949-94d3-923ed8a31ee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "l(x).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuGGvznyVq6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1I6-_g0sbfdu0mZIrsHz1F5nIz0vEzv9w",
      "authorship_tag": "ABX9TyPi+Jt2VVMK5dkZy+NWVfa1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}